{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%matplotlib qt\n",
    "%matplotlib inline\n",
    "\n",
    "'''\n",
    "Camera class is used to:\n",
    "    - calculate calibration parameters for the camera based on a set of calibration images\n",
    "    - store calibration parameters for later use\n",
    "    - read in calibration parameters to save on processing time\n",
    "    - undistort an image using calibration parameters, for later processing\n",
    "    - undistort a set of test images using calibration parameters, for demo purposes\n",
    "'''\n",
    "class Camera():\n",
    "    def __init__(self):\n",
    "        # camera calibration parameters\n",
    "        self.mtx = []\n",
    "        self.dist = []\n",
    "\n",
    "    # calculate camera calibration parameters based on the calibration images\n",
    "    def calculate_calibration_parameters(self):\n",
    "        # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "        objp = np.zeros((6*9,3), np.float32)\n",
    "        objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "        # Arrays to store object points and image points from all the images.\n",
    "        objpoints = [] # 3d points in real world space\n",
    "        imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "        # Make a list of calibration images\n",
    "        images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "        # Step through the list and search for chessboard corners\n",
    "        for fname in images:\n",
    "            img = cv2.imread(fname)\n",
    "            gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "            # Find the chessboard corners\n",
    "            ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "            # If found, add object points, image points\n",
    "            if ret == True:\n",
    "                objpoints.append(objp)\n",
    "                imgpoints.append(corners)\n",
    "\n",
    "                # Draw and display the corners\n",
    "                img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "                cv2.imshow('img',img)\n",
    "                cv2.waitKey(500)\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        if len(objpoints) & len(imgpoints):\n",
    "            # Do camera calibration given object points and image points\n",
    "            ret, self.mtx, self.dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "        # Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "        dist_pickle = {}\n",
    "        dist_pickle[\"mtx\"] = self.mtx\n",
    "        dist_pickle[\"dist\"] = self.dist\n",
    "        pickle.dump( dist_pickle, open( \"camera_cal/camera_calibration_parameters.p\", \"wb\" ) )\n",
    "\n",
    "        print(\"Created new calibration parameters: mtx=\", self.mtx, \"; dist=\", self.dist)\n",
    "\n",
    "\n",
    "    # Read in the saved calibration parameters\n",
    "    def read_calibration_parameters(self):\n",
    "        calibration_file_path = \"camera_cal/camera_calibration_parameters.p\"\n",
    "        if os.path.isfile(calibration_file_path):\n",
    "            dist_pickle = pickle.load( open( calibration_file_path, \"rb\" ) )\n",
    "            self.mtx = dist_pickle[\"mtx\"]\n",
    "            self.dist = dist_pickle[\"dist\"]\n",
    "\n",
    "            print(\"Loaded calibration parameters: mtx=\", self.mtx, \"; dist=\", self.dist)\n",
    "\n",
    "\n",
    "    # read saved calibration parameters or calculate based on the calibration images\n",
    "    def initialize_calibration_parameters(self):\n",
    "        # try to read calibration parameters saved before (speed up processing during development)\n",
    "        self.read_calibration_parameters()\n",
    "\n",
    "        # if saved camera calibration parameters were not found - try to calibrate camera\n",
    "        if not (len(self.mtx) & len(self.dist)):\n",
    "            self.calculate_calibration_parameters()\n",
    "\n",
    "\n",
    "    # if camera calibration parameters are initiaized properly - undistort test images\n",
    "    def undistort_test_images(self):\n",
    "        if len(self.mtx) & len(self.dist):\n",
    "\n",
    "            in_folder = \"test_images/\"\n",
    "            out_folder = \"output_images/\"\n",
    "\n",
    "            if not os.path.exists(out_folder):\n",
    "                os.makedirs(out_folder)\n",
    "\n",
    "            source_files = os.listdir(in_folder)\n",
    "\n",
    "            # Read sample images, undistort and write to the output folder\n",
    "            for source_file in source_files:\n",
    "\n",
    "                source_path = in_folder + source_file\n",
    "                img = cv2.imread(source_path)\n",
    "\n",
    "                undistorted = cv2.undistort(img, self.mtx, self.dist, None, self.mtx)\n",
    "\n",
    "                result_path = out_folder + source_file\n",
    "                print(\"result_path=\", result_path);\n",
    "                cv2.imwrite(result_path, undistorted)\n",
    "\n",
    "                # Draw and display undistorted image\n",
    "                f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "                f.tight_layout()\n",
    "                ax1.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "                ax1.set_title('Original Image', fontsize=50)\n",
    "                ax2.imshow(cv2.cvtColor(undistorted,cv2.COLOR_BGR2RGB))\n",
    "                ax2.set_title('Undistorted Image', fontsize=50)\n",
    "                plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "                plt.show()\n",
    "\n",
    "    # undistort image using the camera calibration parameters\n",
    "    def undistort_image(self, image):\n",
    "        if len(self.mtx) & len(self.dist):\n",
    "            return cv2.undistort(image, self.mtx, self.dist, None, self.mtx)\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And so on and so forth..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_show_images(img1, title1, img2, title2, cmap1=None, cmap2=None):\n",
    "    # Plot the result\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img1, cmap=cmap1)\n",
    "    ax1.set_title(title1, fontsize=50)\n",
    "    ax2.imshow(img2, cmap=cmap2)\n",
    "    ax2.set_title(title2, fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryImage():\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate directional gradient and apply threshold\n",
    "def abs_sobel_thresh(image, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    \n",
    "    # grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # derivative\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    # absolute value\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    \n",
    "    # scale to 0-255\n",
    "    abs_sobel_max = np.max(abs_sobel)\n",
    "    abs_sobel = np.uint8(255*abs_sobel/abs_sobel_max)\n",
    "    \n",
    "    # apply threshold\n",
    "    binary_output = np.zeros_like(abs_sobel)\n",
    "    binary_output[(abs_sobel >= thresh[0]) & (abs_sobel <= thresh[1])] = 1\n",
    "    \n",
    "    # display the result\n",
    "    #debug_show_images(cv2.cvtColor(image,cv2.COLOR_BGR2RGB), 'Original Image', binary_output, 'Thresholded Gradient', cmap2 = 'gray')\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "# Calculate gradient magnitude and apply threshold\n",
    "def mag_thresh(image, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    # 3) Calculate the magnitude \n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    \n",
    "    # grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # derivative\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    # magnitude\n",
    "    sobel = np.zeros_like(sobel_x)\n",
    "    sobel = (sobel_x**2 + sobel_y**2)**(1/2.0)\n",
    "    \n",
    "    # scale to 0-255\n",
    "    sobel_max = np.max(sobel)\n",
    "    sobel = np.uint8(255*sobel/sobel_max)\n",
    "    \n",
    "    # apply threshold\n",
    "    binary_output = np.zeros_like(sobel)\n",
    "    binary_output[(sobel >= mag_thresh[0]) & (sobel <= mag_thresh[1])] = 1\n",
    "\n",
    "    # display the result\n",
    "    #debug_show_images(cv2.cvtColor(image,cv2.COLOR_BGR2RGB), 'Original Image', binary_output, 'Thresholded Magnitude', cmap2 = 'gray')\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "# Calculate gradient direction and apply threshold\n",
    "def dir_threshold(image, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    \n",
    "    # grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # derivative\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    # absolute value and direction of the gradient\n",
    "    grad_direction = np.arctan2(np.absolute(sobel_y), np.absolute(sobel_x))\n",
    "    \n",
    "    # apply threshold\n",
    "    binary_output = np.zeros_like(grad_direction)\n",
    "    binary_output[(grad_direction >= thresh[0]) & (grad_direction <= thresh[1])] = 1\n",
    "    \n",
    "    # display the result\n",
    "    #debug_show_images(cv2.cvtColor(image,cv2.COLOR_BGR2RGB), 'Original Image', binary_output, 'Thresholded Grad. Dir.', cmap2 = 'gray')\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "\n",
    "# calculate binary image based on different gradient thresholds (absolute, magnitude, direction)\n",
    "def gradient_threshold(image):\n",
    "    \n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(image, orient='x', sobel_kernel=3, thresh=(20, 100))\n",
    "    grady = abs_sobel_thresh(image, orient='y', sobel_kernel=3, thresh=(20, 100))\n",
    "    mag_binary = mag_thresh(image, sobel_kernel=9, mag_thresh=(30, 100))\n",
    "    dir_binary = dir_threshold(image, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    \n",
    "    # display the result\n",
    "    #debug_show_images(cv2.cvtColor(image,cv2.COLOR_BGR2RGB), 'Original Image', combined, 'Combined Grad.-Thresh. Image', cmap2 = 'gray')\n",
    "    \n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colour_threshold(image, s_thresh=(170, 255), sx_thresh=(20, 100)):\n",
    "    #image = np.copy(image)\n",
    "    \n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    # Sobel x on luminance channel\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "\n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary == 1) | (sxbinary == 1)] = 1\n",
    "    return combined_binary\n",
    "    \n",
    "    # Stack each channel\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "    return color_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_threshold(gradient_binary, colour_binary):\n",
    "    \n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(gradient_binary)\n",
    "    combined_binary[(gradient_binary == 1) | (colour_binary == 1)] = 1\n",
    "    return combined_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transform(image):\n",
    "    \n",
    "    # calculate region of interest\n",
    "    ysize = image.shape[0]\n",
    "    xsize = image.shape[1]\n",
    "\n",
    "    near_distance = ysize-1\n",
    "    far_distance = ysize*0.645\n",
    "    mid_x = (xsize-1)/2\n",
    "\n",
    "    left_bottom = [0+150, near_distance]\n",
    "    right_bottom = [xsize-1-150, near_distance]\n",
    "\n",
    "    left_apex = [mid_x-75, far_distance]\n",
    "    right_apex = [mid_x+75, far_distance]\n",
    "\n",
    "    img_size = (image.shape[1], image.shape[0])\n",
    "    src = np.float32(\n",
    "        [left_bottom,\n",
    "        left_apex,\n",
    "        right_apex,\n",
    "        right_bottom])\n",
    "    dst = np.float32(\n",
    "        [[0, ysize-1],\n",
    "        [0, 0],\n",
    "        [xsize-1, 0],\n",
    "        [xsize-1, ysize-1]])\n",
    "    \n",
    "    # draw source region\n",
    "    for i in range(0, len(src)-1):\n",
    "        cv2.line(image, (src[i][0], src[i][1]), (src[i+1][0], src[i+1][1]), [255, 0, 0], 2)\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(image, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return warped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = Camera()\n",
    "camera.initialize_calibration_parameters()\n",
    "\n",
    "in_folder = \"test_images/\"\n",
    "out_folder = \"output_images/\"\n",
    "\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "\n",
    "source_files = os.listdir(in_folder)\n",
    "\n",
    "# Read and process sample images\n",
    "for source_file in source_files:\n",
    "\n",
    "    # read test image in\n",
    "    source_path = in_folder + source_file\n",
    "    img = cv2.imread(source_path)\n",
    "\n",
    "    # undistort according to the camera calibration parameters\n",
    "    undistorted = camera.undistort_image(img)\n",
    "    debug_show_images(cv2.cvtColor(img,cv2.COLOR_BGR2RGB), 'Original Image', cv2.cvtColor(undistorted,cv2.COLOR_BGR2RGB), 'Undistorted Image')\n",
    "\n",
    "    # write undostorted image to output folder, if needed\n",
    "    result_path = out_folder + 'undistorted_' + source_file\n",
    "    print(\"Writing to result_path=\", result_path);\n",
    "    cv2.imwrite(result_path, undistorted)\n",
    "    \n",
    "    # find threholded binary image using gradients\n",
    "    thresholded_grad = gradient_threshold(undistorted)\n",
    "    #debug_show_images(cv2.cvtColor(undistorted,cv2.COLOR_BGR2RGB), 'Undistorted Image', thresholded_grad, 'Thresholded by Gradients', cmap2 = 'gray')\n",
    "    \n",
    "    # another try with colour transformation and gradient\n",
    "    thresholded_col = colour_threshold(undistorted)\n",
    "    #debug_show_images(cv2.cvtColor(undistorted,cv2.COLOR_BGR2RGB), 'Undistorted Image', thresholded_col, 'Thresholded by Colour', cmap2 = 'gray')\n",
    "    \n",
    "    # combine into a single threholded binary image\n",
    "    combined_binary = combined_threshold(thresholded_grad, thresholded_col)\n",
    "    debug_show_images(cv2.cvtColor(undistorted,cv2.COLOR_BGR2RGB), 'Undistorted Image', combined_binary, 'Thresholded Image', cmap2 = 'gray')\n",
    "\n",
    "    # write threholded image to output folder, if needed\n",
    "    result_path = out_folder + 'threholded_' + source_file\n",
    "    print(\"Writing to result_path=\", result_path);\n",
    "    cv2.imwrite(result_path, combined_binary * 255)\n",
    "    \n",
    "    warped_image = perspective_transform(undistorted)\n",
    "    debug_show_images(cv2.cvtColor(undistorted,cv2.COLOR_BGR2RGB), 'Undistorted Image', cv2.cvtColor(warped_image,cv2.COLOR_BGR2RGB), 'Warped Image')\n",
    "\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
