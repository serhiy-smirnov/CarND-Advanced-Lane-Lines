{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%matplotlib qt\n",
    "%matplotlib inline\n",
    "\n",
    "'''\n",
    "Camera class is used to:\n",
    "    - calculate calibration parameters for the camera based on a set of calibration images\n",
    "    - store calibration parameters for later use\n",
    "    - read in calibration parameters to save on processing time\n",
    "    - undistort an image using calibration parameters, for later processing\n",
    "    - undistort a set of test images using calibration parameters, for demo purposes\n",
    "'''\n",
    "class Camera():\n",
    "    def __init__(self):\n",
    "        # camera calibration parameters\n",
    "        self.mtx = []\n",
    "        self.dist = []\n",
    "\n",
    "    # calculate camera calibration parameters based on the calibration images\n",
    "    def calculate_calibration_parameters(self):\n",
    "        # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "        objp = np.zeros((6*9,3), np.float32)\n",
    "        objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "        # Arrays to store object points and image points from all the images.\n",
    "        objpoints = [] # 3d points in real world space\n",
    "        imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "        # Make a list of calibration images\n",
    "        images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "        # Step through the list and search for chessboard corners\n",
    "        for fname in images:\n",
    "            img = cv2.imread(fname)\n",
    "            gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "            # Find the chessboard corners\n",
    "            ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "            # If found, add object points, image points\n",
    "            if ret == True:\n",
    "                objpoints.append(objp)\n",
    "                imgpoints.append(corners)\n",
    "\n",
    "                # Draw and display the corners\n",
    "                img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "                cv2.imshow('img',img)\n",
    "                cv2.waitKey(500)\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        if len(objpoints) & len(imgpoints):\n",
    "            # Do camera calibration given object points and image points\n",
    "            ret, self.mtx, self.dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "        # Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "        dist_pickle = {}\n",
    "        dist_pickle[\"mtx\"] = self.mtx\n",
    "        dist_pickle[\"dist\"] = self.dist\n",
    "        pickle.dump( dist_pickle, open( \"camera_cal/camera_calibration_parameters.p\", \"wb\" ) )\n",
    "\n",
    "        print(\"Created new calibration parameters: mtx=\", self.mtx, \"; dist=\", self.dist)\n",
    "\n",
    "\n",
    "    # Read in the saved calibration parameters\n",
    "    def read_calibration_parameters(self):\n",
    "        calibration_file_path = \"camera_cal/camera_calibration_parameters.p\"\n",
    "        if os.path.isfile(calibration_file_path):\n",
    "            dist_pickle = pickle.load( open( calibration_file_path, \"rb\" ) )\n",
    "            self.mtx = dist_pickle[\"mtx\"]\n",
    "            self.dist = dist_pickle[\"dist\"]\n",
    "\n",
    "            print(\"Loaded calibration parameters: mtx=\", self.mtx, \"; dist=\", self.dist)\n",
    "\n",
    "\n",
    "    # read saved calibration parameters or calculate based on the calibration images\n",
    "    def initialize_calibration_parameters(self):\n",
    "        # try to read calibration parameters saved before (speed up processing during development)\n",
    "        self.read_calibration_parameters()\n",
    "\n",
    "        # if saved camera calibration parameters were not found - try to calibrate camera\n",
    "        if not (len(self.mtx) & len(self.dist)):\n",
    "            self.calculate_calibration_parameters()\n",
    "\n",
    "\n",
    "    # if camera calibration parameters are initiaized properly - undistort test images\n",
    "    def undistort_test_images(self):\n",
    "        if len(self.mtx) & len(self.dist):\n",
    "\n",
    "            in_folder = \"test_images/\"\n",
    "            out_folder = \"output_images/\"\n",
    "\n",
    "            if not os.path.exists(out_folder):\n",
    "                os.makedirs(out_folder)\n",
    "\n",
    "            source_files = os.listdir(in_folder)\n",
    "\n",
    "            # Read sample images, undistort and write to the output folder\n",
    "            for source_file in source_files:\n",
    "\n",
    "                source_path = in_folder + source_file\n",
    "                img = cv2.imread(source_path)\n",
    "\n",
    "                undistorted = cv2.undistort(img, self.mtx, self.dist, None, self.mtx)\n",
    "\n",
    "                result_path = out_folder + source_file\n",
    "                print(\"result_path=\", result_path);\n",
    "                cv2.imwrite(result_path, undistorted)\n",
    "\n",
    "                # Draw and display undistorted image\n",
    "                f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "                f.tight_layout()\n",
    "                ax1.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "                ax1.set_title('Original Image', fontsize=50)\n",
    "                ax2.imshow(cv2.cvtColor(undistorted,cv2.COLOR_BGR2RGB))\n",
    "                ax2.set_title('Undistorted Image', fontsize=50)\n",
    "                plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "                plt.show()\n",
    "\n",
    "    # undistort image using the camera calibration parameters\n",
    "    def undistort_image(self, image):\n",
    "        if len(self.mtx) & len(self.dist):\n",
    "            return cv2.undistort(image, self.mtx, self.dist, None, self.mtx)\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And so on and so forth..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_show_images(img1, title1, img2, title2, cmap1=None, cmap2=None):\n",
    "    # Plot the result\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img1, cmap=cmap1)\n",
    "    ax1.set_title(title1, fontsize=50)\n",
    "    ax1.tick_params(labelbottom=True, labeltop=True, labelleft=True, labelright=True,\n",
    "                     bottom=True, top=True, left=True, right=True)\n",
    "    ax2.imshow(img2, cmap=cmap2)\n",
    "    ax2.set_title(title2, fontsize=50)\n",
    "    ax2.tick_params(labelbottom=True, labeltop=True, labelleft=True, labelright=True,\n",
    "                     bottom=True, top=True, left=True, right=True)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryImage():\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate directional gradient and apply threshold\n",
    "def abs_sobel_threshold(gray, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    # 2) Take the absolute value of the derivative or gradient\n",
    "    # 3) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    # 4) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    # 5) Return this mask as your binary_output image\n",
    "    \n",
    "    # derivative\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    # absolute value\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    \n",
    "    # scale to 0-255\n",
    "    abs_sobel_max = np.max(abs_sobel)\n",
    "    abs_sobel = np.uint8(255*abs_sobel/abs_sobel_max)\n",
    "    \n",
    "    # apply threshold\n",
    "    binary_output = np.zeros_like(abs_sobel)\n",
    "    binary_output[(abs_sobel >= thresh[0]) & (abs_sobel <= thresh[1])] = 1\n",
    "    \n",
    "    # display the result\n",
    "    #debug_show_images(image, 'Original Image', binary_output, 'Thresholded Gradient by ' + orient, cmap2 = 'gray')\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "# Calculate gradient magnitude and apply threshold\n",
    "def mag_threshold(gray, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "\n",
    "    # Apply the following steps to img\n",
    "    # 1) Take the gradient in x and y separately\n",
    "    # 2) Calculate the magnitude \n",
    "    # 3) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    # 4) Create a binary mask where mag thresholds are met\n",
    "    # 5) Return this mask as your binary_output image\n",
    "    \n",
    "    # derivative\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    # magnitude\n",
    "    sobel = np.zeros_like(sobel_x)\n",
    "    sobel = (sobel_x**2 + sobel_y**2)**(1/2.0)\n",
    "    \n",
    "    # scale to 0-255\n",
    "    sobel_max = np.max(sobel)\n",
    "    sobel = np.uint8(255*sobel/sobel_max)\n",
    "    \n",
    "    # apply threshold\n",
    "    binary_output = np.zeros_like(sobel)\n",
    "    binary_output[(sobel >= mag_thresh[0]) & (sobel <= mag_thresh[1])] = 1\n",
    "\n",
    "    # display the result\n",
    "    #debug_show_images(image, 'Original Image', binary_output, 'Thresholded Magnitude', cmap2 = 'gray')\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "# Calculate gradient direction and apply threshold\n",
    "def dir_threshold(gray, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Take the gradient in x and y separately\n",
    "    # 2) Take the absolute value of the x and y gradients\n",
    "    # 3) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    # 4) Create a binary mask where direction thresholds are met\n",
    "    # 5) Return this mask as your binary_output image\n",
    "    \n",
    "    # derivative\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    # absolute value and direction of the gradient\n",
    "    grad_direction = np.arctan2(np.absolute(sobel_y), np.absolute(sobel_x))\n",
    "    \n",
    "    # apply threshold\n",
    "    binary_output = np.zeros_like(grad_direction)\n",
    "    binary_output[(grad_direction >= thresh[0]) & (grad_direction <= thresh[1])] = 1\n",
    "    \n",
    "    # display the result\n",
    "    #debug_show_images(image, 'Original Image', binary_output, 'Thresholded Grad. Dir.', cmap2 = 'gray')\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "\n",
    "# calculate binary image based on different gradient thresholds (absolute, magnitude, direction)\n",
    "def gradient_threshold(image):\n",
    "    \n",
    "    # each of the thresholding functions works with grayscale image\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_threshold(gray, orient='x', sobel_kernel=3, thresh=(20, 100))\n",
    "    grady = abs_sobel_threshold(gray, orient='y', sobel_kernel=3, thresh=(20, 100))\n",
    "    mag_binary = mag_threshold(gray, sobel_kernel=9, mag_thresh=(30, 100))\n",
    "    dir_binary = dir_threshold(gray, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    \n",
    "    # display the result\n",
    "    #debug_show_images(image, 'Original Image', combined, 'Combined Grad.-Thresh. Image', cmap2 = 'gray')\n",
    "    \n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colour_threshold(image, s_thresh=(170, 255), sx_thresh=(20, 100)):\n",
    "    #image = np.copy(image)\n",
    "    \n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    # Sobel x on luminance channel\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "\n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary == 1) | (sxbinary == 1)] = 1\n",
    "    return combined_binary\n",
    "    \n",
    "    # Stack each channel\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "    return color_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_threshold(gradient_binary, colour_binary):\n",
    "    \n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(gradient_binary)\n",
    "    combined_binary[(gradient_binary == 1) | (colour_binary == 1)] = 1\n",
    "    #combined_binary[(colour_binary == 1)] = 1\n",
    "    return combined_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerspectiveTransform():\n",
    "    def __init__(self, xsize, ysize):\n",
    "\n",
    "        self.xsize = xsize\n",
    "        self.ysize = ysize\n",
    "        \n",
    "        # define region of interest\n",
    "        near_distance = ysize-1\n",
    "        far_distance = ysize*0.645\n",
    "\n",
    "        left_bottom = [0+70, near_distance]\n",
    "        right_bottom = [xsize-1-70, near_distance]\n",
    "\n",
    "        left_apex = [xsize/2-89, far_distance]\n",
    "        right_apex = [xsize/2-1+89, far_distance]\n",
    "\n",
    "        src = np.float32(\n",
    "            [left_bottom,\n",
    "            left_apex,\n",
    "            right_apex,\n",
    "            right_bottom])\n",
    "        dst = np.float32(\n",
    "            [[0, ysize-1],\n",
    "            [0, 0],\n",
    "            [xsize-1, 0],\n",
    "            [xsize-1, ysize-1]])\n",
    "\n",
    "        # calculate perspective matrix and inverse perspective matrix\n",
    "        self.M = cv2.getPerspectiveTransform(src, dst)\n",
    "        self.Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "        \n",
    "    def warp_to_birds_eye_view(self, image):\n",
    "        # draw source region into the original image\n",
    "        # for debug purposes only!\n",
    "        # must be disabled after the region is set, otherwise the detection pipeline works incorrectly!\n",
    "        #for i in range(0, len(src)-1):\n",
    "        #    cv2.line(image, (src[i][0], src[i][1]), (src[i+1][0], src[i+1][1]), [255, 0, 0], 2)\n",
    "        return cv2.warpPerspective(image, self.M, (self.xsize, self.ysize), flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    def warp_to_perspective(self, image):\n",
    "        return cv2.warpPerspective(image, self.Minv, (self.xsize, self.ysize), flags=cv2.INTER_LINEAR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    \n",
    "    def __init__(self, side = \"left\"):\n",
    "        \n",
    "        # which side of  the lane the line is on\n",
    "        # used to detect initial line position on the histogram and for different colouring\n",
    "        self.side = side\n",
    "        \n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]\n",
    "        \n",
    "        # number of previous detections to keep for stabilization\n",
    "        self.stabilization_history = 5\n",
    "        \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None\n",
    "        \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "        \n",
    "        # Parameters for the sliding window search\n",
    "        # The threshold for the histogram value\n",
    "        self.histogram_threshold = 50\n",
    "        # The number of sliding windows\n",
    "        self.nwindows = 9\n",
    "        # The width of the windows +/- margin\n",
    "        self.margin_sliding_window = 100\n",
    "        # Minimum number of pixels found to recenter window\n",
    "        self.minpix = 50\n",
    "        \n",
    "        # Parameters for the search around polynomial\n",
    "        # The width of the margin around the previous polynomial to search\n",
    "        self.margin_polynomial_search = 100\n",
    "        \n",
    "        self.detection_confidence = 0\n",
    "        \n",
    "        # Define conversions in x and y from pixels space to meters\n",
    "        self.ym_per_pix = 27/720 # meters per pixel in y dimension\n",
    "        self.xm_per_pix = 3.7/1000 # meters per pixel in x dimension\n",
    "\n",
    "\n",
    "        \n",
    "    def measure_curvature_pixels(self, y_eval):\n",
    "        '''\n",
    "        Calculates the curvature of polynomial functions in pixels.\n",
    "        '''\n",
    "        curverad = 0\n",
    "        \n",
    "        if self.detected:\n",
    "            # Calculate radius of curvature\n",
    "            curverad = ((1 + (2*self.best_fit[0]*y_eval + self.best_fit[1])**2)**1.5) / np.abs(2*self.best_fit[0])\n",
    "\n",
    "        return curverad\n",
    "\n",
    "    def measure_curvature_real(self, y_eval):\n",
    "        '''\n",
    "        Calculates the curvature of polynomial functions in meters.\n",
    "        '''\n",
    "        self.radius_of_curvature = 0\n",
    "\n",
    "        if self.detected:\n",
    "            y = y_eval * self.ym_per_pix\n",
    "            a = self.best_fit[0] * self.xm_per_pix / (self.ym_per_pix ** 2)\n",
    "            b = self.best_fit[1] * (self.xm_per_pix / self.ym_per_pix)\n",
    "\n",
    "            # Calculate radius of curvature\n",
    "            self.radius_of_curvature = ((1 + (2*a*y + b)**2)**1.5) / np.abs(2*a)\n",
    "\n",
    "        return self.radius_of_curvature\n",
    "\n",
    "    # find lane pixels and color them\n",
    "    def find_lane_pixels_histohramm_sliding_window(self, binary_warped, out_img):\n",
    "\n",
    "        # Take a histogram of the bottom half of the image\n",
    "        histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "        #plt.plot(histogram)\n",
    "        #plt.show()\n",
    "        # Find the peak of the left or right halves of the histogram (depending on the initial parameter 'side')\n",
    "        # These will be the starting point for the left or right lines\n",
    "        midpoint = np.int(histogram.shape[0]//2)\n",
    "        x_base = np.argmax(histogram[:midpoint]) if self.side == \"left\" else np.argmax(histogram[midpoint:]) + midpoint\n",
    "        #print(\"side=\", self.side, \"; midpoint=\", midpoint, \"; x_base=\", x_base, \"; histogram[x_base]=\", histogram[x_base])\n",
    "        \n",
    "        # check if the histogram values make sense\n",
    "        if histogram[x_base] < self.histogram_threshold:\n",
    "            self.detected = False\n",
    "            return [], []\n",
    "\n",
    "        # Set height of windows - based on nwindows above and image shape\n",
    "        window_height = np.int(binary_warped.shape[0]//self.nwindows)\n",
    "        # Identify the x and y positions of all nonzero pixels in the image\n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        #print(nonzeroy, nonzerox)\n",
    "        # Current positions to be updated later for each window in nwindows\n",
    "        x_current = x_base\n",
    "\n",
    "        # Create empty lists to receive lane pixel indices\n",
    "        lane_inds = []\n",
    "\n",
    "        # Step through the windows one by one\n",
    "        for window in range(self.nwindows):\n",
    "            # Identify window boundaries in x and y (and right and left)\n",
    "            win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "            win_y_high = binary_warped.shape[0] - window*window_height\n",
    "            ### Find the four below boundaries of the window ###\n",
    "            win_x_low = x_current - self.margin_sliding_window\n",
    "            win_x_high = x_current + self.margin_sliding_window\n",
    "            #print(\"win_y_low=\", win_y_low, \"win_y_high=\", win_y_high, \"win_x_low=\", win_x_low, \"win_x_high=\", win_x_high)\n",
    "\n",
    "            # Draw the window on the visualization image\n",
    "            cv2.rectangle(out_img, (win_x_low,win_y_low), (win_x_high,win_y_high), (0,255,0), 2) \n",
    "\n",
    "            ### Identify the nonzero pixels in x and y within the window ###\n",
    "            #print(len(nonzeroy), len(nonzerox))\n",
    "            good_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "                    (nonzerox >= win_x_low) & (nonzerox < win_x_high)).nonzero()[0]\n",
    "\n",
    "            # Append these indices to the lists\n",
    "            lane_inds.append(good_inds)\n",
    "\n",
    "            ### If you found > minpix pixels, recenter next window `x_current` on their mean position ###\n",
    "            #print(len(good_inds))\n",
    "            if len(good_inds) > self.minpix:\n",
    "                x_current = np.int(np.mean(nonzerox[good_inds]))\n",
    "\n",
    "        # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "        try:\n",
    "            lane_inds = np.concatenate(lane_inds)\n",
    "        except ValueError:\n",
    "            # Avoids an error if the above is not implemented fully\n",
    "            pass\n",
    "\n",
    "        # Extract left and right line pixel positions\n",
    "        x = nonzerox[lane_inds]\n",
    "        y = nonzeroy[lane_inds]\n",
    "        \n",
    "        self.detection_confidence = len(lane_inds)\n",
    "\n",
    "        ## Visualization ##\n",
    "        # Color the left and right lane regions\n",
    "        out_img[y, x] = [255, 0, 0] if self.side == \"left\" else [0, 0, 255]\n",
    "\n",
    "        self.detected = True\n",
    "        return x, y\n",
    "\n",
    "    # find lane pixels and color them\n",
    "    def find_lane_pixels_search_around_polynomial(self, binary_warped, out_img):\n",
    "\n",
    "        # check if there is a previous polynomial detection available\n",
    "        if len(self.best_fit) < 3:\n",
    "            self.detected = False\n",
    "            return [], []\n",
    "\n",
    "        # Grab activated pixels\n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "\n",
    "        ### Set the area of search based on activated x-values ###\n",
    "        ### within the +/- margin of our polynomial function ###\n",
    "        ploty = nonzeroy\n",
    "        fitx = self.best_fit[0]*ploty**2 + self.best_fit[1]*ploty + self.best_fit[2]\n",
    "        lane_inds = ((nonzerox >= (fitx-self.margin_polynomial_search)) & (nonzerox < (fitx+self.margin_polynomial_search)))\n",
    "        \n",
    "        self.detection_confidence = len(lane_inds)\n",
    "\n",
    "        # Again, extract left and right line pixel positions\n",
    "        x = nonzerox[lane_inds]\n",
    "        y = nonzeroy[lane_inds] \n",
    "\n",
    "        ## Visualization ##\n",
    "        # Color the lane pixels\n",
    "        out_img[y, x] = [255, 0, 0] if self.side == \"left\" else [0, 0, 255]\n",
    "        # Generate two lines to mark polygon for illustration of the search window area\n",
    "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "        # And draw the lines onto the warped image\n",
    "        # on the left\n",
    "        line_window1 = np.array([np.transpose(np.vstack([fitx-self.margin_polynomial_search-2, ploty]))])\n",
    "        line_window2 = np.array([np.flipud(np.transpose(np.vstack([fitx-self.margin_polynomial_search+2, ploty])))])\n",
    "        line_pts = np.hstack((line_window1, line_window2))\n",
    "        cv2.fillPoly(out_img, np.int_([line_pts]), (0,255, 0))\n",
    "        # on the right\n",
    "        line_window1 = np.array([np.transpose(np.vstack([fitx+self.margin_polynomial_search-2, ploty]))])\n",
    "        line_window2 = np.array([np.flipud(np.transpose(np.vstack([fitx+self.margin_polynomial_search+2, ploty])))])\n",
    "        line_pts = np.hstack((line_window1, line_window2))\n",
    "        cv2.fillPoly(out_img, np.int_([line_pts]), (0,255, 0))\n",
    "        \n",
    "        self.detected = True\n",
    "        return x, y\n",
    "\n",
    "    def fit_polynomial(self, img_shape, x, y):\n",
    "\n",
    "        ### Fit a second order polynomial to each using `np.polyfit` ###\n",
    "        fit = np.polyfit(y, x, 2)\n",
    "        #print(x, y, fit)\n",
    "\n",
    "        # Generate x and y values for plotting\n",
    "        self.ally = np.linspace(0, img_shape[0]-1, img_shape[0] )\n",
    "        try:\n",
    "            self.allx = fit[0]*self.ally**2 + fit[1]*self.ally + fit[2]\n",
    "            # add new polynomial detection into the stabilization history list\n",
    "            self.current_fit.insert(0, fit)\n",
    "            # trim stabilization history list to the configured size\n",
    "            if(len(self.current_fit) > self.stabilization_history):\n",
    "                self.current_fit.pop()\n",
    "            # update best fit polynomial parameters\n",
    "            self.best_fit = fit\n",
    "            # flag successful detection\n",
    "            self.detected = True\n",
    "        except TypeError:\n",
    "            # Avoids an error if `fit` are still none or incorrect\n",
    "            print('The function failed to fit a line!')\n",
    "            self.allx = 1*self.ally**2 + 1*self.ally\n",
    "            self.detected = False\n",
    "\n",
    "        #print(\"self.allx=\", self.allx, \"; self.ally=\", self.ally)\n",
    "\n",
    "    def visualize_lines(self, out_img):\n",
    "        # Plot the polynomial lines onto the image\n",
    "        # Generate a polygon to illustrate the polinomial found\n",
    "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "        line_window1 = np.array([np.transpose(np.vstack([self.allx-2, self.ally]))])\n",
    "        line_window2 = np.array([np.flipud(np.transpose(np.vstack([self.allx+2, self.ally])))])\n",
    "        line_pts = np.hstack((line_window1, line_window2))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(out_img, np.int_([line_pts]), (255,255, 0))\n",
    "\n",
    "    def find_line(self, binary_warped, out_img):\n",
    "\n",
    "        # if lane was detected in the previous image - try to search around polynomial\n",
    "        if self.detected:\n",
    "            \n",
    "            # find pixels along the polynomial\n",
    "            x, y = self.find_lane_pixels_search_around_polynomial(binary_warped, out_img)\n",
    "            \n",
    "            # if pixels were found\n",
    "            if self.detected:\n",
    "                \n",
    "                # fit polynomial\n",
    "                self.fit_polynomial(binary_warped.shape, x, y)\n",
    "            \n",
    "        # if there's no detection from the previous frame OR detection based on the previous frame failed - try sliding window\n",
    "        if not self.detected:\n",
    "            \n",
    "            # find pixels using histogram and sliding window approach\n",
    "            x, y = self.find_lane_pixels_histohramm_sliding_window(binary_warped, out_img)\n",
    "\n",
    "            # if pixels were found\n",
    "            if self.detected:\n",
    "                \n",
    "                # fit polynomial\n",
    "                self.fit_polynomial(binary_warped.shape, x, y)\n",
    "\n",
    "        # if detection is successful - then measure and display curvature\n",
    "        if self.detected:\n",
    "        \n",
    "            # visualize polynomial\n",
    "            self.visualize_lines(out_img)\n",
    "            \n",
    "            # Define y-value where we want radius of curvature\n",
    "            # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "            y_eval = np.max(self.ally)\n",
    "\n",
    "            # measure and display curvature radius in pixels\n",
    "            #curvature_px = self.measure_curvature_pixels(y_eval)\n",
    "            #print('curvature radius = ', curvature_px, 'px')\n",
    "\n",
    "            # calculate and display curvature radius in meters\n",
    "            y = y_eval * self.ym_per_pix\n",
    "            a = self.best_fit[0] * self.xm_per_pix / (self.ym_per_pix ** 2)\n",
    "            b = self.best_fit[1] * (self.xm_per_pix / self.ym_per_pix)\n",
    "            self.radius_of_curvature = ((1 + (2*a*y + b)**2)**1.5) / np.abs(2*a)\n",
    "            #print('self.radius_of_curvature = ', self.radius_of_curvature, 'm')\n",
    "            \n",
    "            # calculate distance from the middle of the car to the line\n",
    "            midpoint = binary_warped.shape[1]//2\n",
    "            line_point = self.allx[-1]\n",
    "            self.line_base_pos = abs(midpoint - line_point) * self.xm_per_pix\n",
    "            #print(\"midpoint=\", midpoint, \"; line_point=\", line_point, \"; self.line_base_pos=\", self.line_base_pos)\n",
    "        \n",
    "        else:\n",
    "            self.radius_of_curvature = 0\n",
    "            self.line_base_pos = 0\n",
    "\n",
    "        return self.detected\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lane():\n",
    "    def __init__(self):\n",
    "        self.line_left = Line(\"left\")\n",
    "        self.line_right = Line(\"right\")\n",
    "        # last detected lane width\n",
    "        self.lane_width = 3.7\n",
    "        \n",
    "    def find_lane(self, binary_warped):\n",
    "        # Create an output image to draw on and visualize the result\n",
    "        out_img = np.dstack((binary_warped, binary_warped, binary_warped)) * 255\n",
    "        \n",
    "        self.line_left.find_line(binary_warped, out_img)\n",
    "        self.line_right.find_line(binary_warped, out_img)\n",
    "        \n",
    "        self.validate_lane()\n",
    "            \n",
    "        return out_img\n",
    "    \n",
    "    def validate_lane(self):\n",
    "        # TODO:\n",
    "        # 1) calculate confidence based on number of pixels used for calculation\n",
    "        # 2) compare curvature radius\n",
    "        # 3) introduce threshold for difference between curvature radius between lines\n",
    "        # 4) if the threshold is exceeded, reject detection (set self.detected to false)\n",
    "        # 5) check direction of the curvature\n",
    "        # 6) introduce threshold for the curvature difference in case of different direction (may be a smaller value)\n",
    "        # 7) if the line with less confidence is curved into a different direction AND the threshold is exceeded, reject detection\n",
    "        if self.line_left.detected and self.line_right.detected:\n",
    "            ratio = abs(self.line_left.radius_of_curvature/self.line_right.radius_of_curvature)\n",
    "            if ratio < 0: ratio = 1.0/ratio \n",
    "            if ratio > 5:\n",
    "                #print(\"line_left.radius_of_curvature=\", self.line_left.radius_of_curvature, \"; line_right.radius_of_curvature=\", self.line_right.radius_of_curvature)\n",
    "                if self.line_left.detection_confidence < self.line_right.detection_confidence:\n",
    "                    self.line_left.detected = False\n",
    "                    #print(\"Rejecting left line detection\")\n",
    "                else:\n",
    "                    self.line_right.detected = False\n",
    "                    #print(\"Rejecting right line detection\")\n",
    "            if np.sign(self.line_left.current_fit[0][0]) != np.sign(self.line_right.current_fit[0][0]):\n",
    "                #print(\"a_left=\", self.line_left.current_fit[0][0], \"; a_right=\", self.line_right.current_fit[0][0])\n",
    "                ratio = abs(self.line_left.radius_of_curvature/self.line_right.radius_of_curvature)\n",
    "                if ratio < 0: ratio = 1.0/ratio \n",
    "                if ratio > 2:\n",
    "                    #print(\"line_left.radius_of_curvature=\", self.line_left.radius_of_curvature, \"; line_right.radius_of_curvature=\", self.line_right.radius_of_curvature)\n",
    "                    if self.line_left.detection_confidence < self.line_right.detection_confidence:\n",
    "                        self.line_left.detected = False\n",
    "                        #print(\"Rejecting left line detection\")\n",
    "                    else:\n",
    "                        self.line_right.detected = False\n",
    "                        #print(\"Rejecting right line detection\")\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def generate_display_lane(self, binary_warped):\n",
    "        \n",
    "        # Create an image to draw the lines on\n",
    "        warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "        if self.line_left.detected and self.line_right.detected:\n",
    "            # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "            pts_left = np.array([np.transpose(np.vstack([self.line_left.allx, self.line_left.ally]))])\n",
    "            pts_right = np.array([np.flipud(np.transpose(np.vstack([self.line_right.allx, self.line_right.ally])))])\n",
    "        \n",
    "        # if one of the lanes is not detected - use the other's lane polynomial shifted by the last detected lane width\n",
    "        else:\n",
    "            if self.line_left.detected:\n",
    "                pts_left = np.array([np.transpose(np.vstack([self.line_left.allx, self.line_left.ally]))])\n",
    "                # substitute from the other lane\n",
    "                right_allx = self.line_left.current_fit[0][0]*self.line_left.ally**2 + self.line_left.current_fit[0][1]*self.line_left.ally + self.line_left.current_fit[0][2] + self.lane_width/self.line_left.xm_per_pix\n",
    "                pts_right = np.array([np.flipud(np.transpose(np.vstack([right_allx, self.line_left.ally])))])\n",
    "            elif self.line_right.detected:\n",
    "                pts_right = np.array([np.flipud(np.transpose(np.vstack([self.line_right.allx, self.line_right.ally])))])\n",
    "                # substitute from the other lane\n",
    "                left_allx = self.line_right.current_fit[0][0]*self.line_right.ally**2 + self.line_right.current_fit[0][1]*self.line_right.ally + self.line_right.current_fit[0][2] - self.lane_width/self.line_right.xm_per_pix\n",
    "                pts_left = np.array([np.flipud(np.transpose(np.vstack([left_allx, self.line_right.ally])))])\n",
    "            else:\n",
    "                return color_warp\n",
    "\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "        \n",
    "        return color_warp\n",
    "    \n",
    "    def display_lane_properties(self, image):\n",
    "        \n",
    "        if self.line_left.detected and self.line_right.detected:\n",
    "            \n",
    "            self.lane_width = self.line_left.line_base_pos + self.line_right.line_base_pos\n",
    "            lane_curvature = (self.line_left.radius_of_curvature + self.line_right.radius_of_curvature) / 2\n",
    "            \n",
    "            message = \"Lane width is \" + str(round(self.lane_width, 2)) + \" m\"\n",
    "            cv2.putText(image, message, (10,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "            \n",
    "            message = \"Lane curvature is \" + str(round(lane_curvature, 2)) + \" m\"\n",
    "            cv2.putText(image, message, (10,100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "            \n",
    "            if self.line_left.line_base_pos > self.line_right.line_base_pos:\n",
    "                message = \"The car is \" + str(round(self.line_left.line_base_pos - self.lane_width / 2, 2)) + \" m to the right of the lane\"\n",
    "            elif self.line_left.line_base_pos < self.line_right.line_base_pos:\n",
    "                message = \"The car is \" + str(round(self.line_right.line_base_pos - self.lane_width / 2, 2)) + \" m to the left of the lane\"\n",
    "            else:\n",
    "                message = \"The car is exactly in the middle of the lane!\"\n",
    "            cv2.putText(image, message, (10,150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "        \n",
    "        else:\n",
    "            message = \"One of the lines was not found! Assuming lane width of \" + str(round(self.lane_width, 2)) + \" m\"\n",
    "            cv2.putText(image, message, (10,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor():\n",
    "    \n",
    "    def __init__(self, camera, xsize, ysize, show_debug_images = False, write_undistorted = False, write_thresholded = False, write_birds_eye_view = False, write_result = False):\n",
    "        # create lane detector object\n",
    "        self.camera = camera\n",
    "        self.transform = PerspectiveTransform(xsize, ysize)\n",
    "        self.show_debug_images = show_debug_images\n",
    "        self.write_undistorted = write_undistorted\n",
    "        self.write_thresholded = write_thresholded\n",
    "        self.write_birds_eye_view = write_birds_eye_view\n",
    "        self.write_result = write_result\n",
    "        self.lane = Lane()\n",
    "    \n",
    "    def process_image(self, img):\n",
    "        # undistort according to the camera calibration parameters\n",
    "        undistorted = self.camera.undistort_image(img)\n",
    "        if self.show_debug_images:\n",
    "            #debug_show_images(img, 'Original Image', undistorted, 'Undistorted Image')\n",
    "            pass\n",
    "\n",
    "        # write undostorted image to output folder, if needed\n",
    "        if self.write_undistorted:\n",
    "            result_path = out_folder + 'undistorted_' + source_file\n",
    "            print(\"Writing to result_path=\", result_path);\n",
    "            cv2.imwrite(result_path, undistorted)\n",
    "\n",
    "        # find threholded binary image using gradients\n",
    "        thresholded_grad = gradient_threshold(undistorted)\n",
    "        if self.show_debug_images:\n",
    "            #debug_show_images(undistorted, 'Undistorted Image', thresholded_grad, 'Thresholded by Gradients', cmap2 = 'gray')\n",
    "            pass\n",
    "\n",
    "        # another try with colour transformation and gradient\n",
    "        thresholded_col = colour_threshold(undistorted)\n",
    "        if self.show_debug_images:\n",
    "            #debug_show_images(undistorted, 'Undistorted Image', thresholded_col, 'Thresholded by Colour', cmap2 = 'gray')\n",
    "            pass\n",
    "\n",
    "        # combine into a single threholded binary image\n",
    "        combined_binary = combined_threshold(thresholded_grad, thresholded_col)\n",
    "        if self.show_debug_images:\n",
    "            #debug_show_images(undistorted, 'Undistorted Image', combined_binary, 'Thresholded Image', cmap2 = 'gray')\n",
    "            pass\n",
    "\n",
    "        # write threholded image to output folder, if needed\n",
    "        if self.write_thresholded:\n",
    "            result_path = out_folder + 'threholded_' + source_file\n",
    "            print(\"Writing to result_path=\", result_path);\n",
    "            cv2.imwrite(result_path, combined_binary * 255)\n",
    "\n",
    "        warped_image = self.transform.warp_to_birds_eye_view(undistorted)\n",
    "        if self.show_debug_images:\n",
    "            #debug_show_images(undistorted, 'Undistorted Image', warped_image, 'Warped Image')\n",
    "            pass\n",
    "\n",
    "        if self.write_birds_eye_view:\n",
    "            result_path = out_folder + 'warped_' + source_file\n",
    "            print(\"Writing to result_path=\", result_path);\n",
    "            cv2.imwrite(result_path, warped_image)\n",
    "\n",
    "        warped_binary = self.transform.warp_to_birds_eye_view(combined_binary)\n",
    "        if self.show_debug_images:\n",
    "            #debug_show_images(combined_binary, 'Thresholded Image', warped_binary * 255, 'Warped Binary Image', cmap1 = 'gray', cmap2 = 'gray')\n",
    "            pass\n",
    "\n",
    "        # try to find lane in the given picture\n",
    "        out_img = self.lane.find_lane(warped_binary)\n",
    "        if self.show_debug_images:\n",
    "            #debug_show_images(warped_binary * 255, 'Warped Binary Image', out_img.astype(int), 'Lane Detected', cmap1 = 'gray')\n",
    "            pass\n",
    "\n",
    "        # generate image with detected lane (in birds eye view)\n",
    "        warped_lane_image = self.lane.generate_display_lane(warped_binary)\n",
    "        # warp the image with detected lane back to original image space using inverse perspective matrix (Minv)\n",
    "        perspective_lane_image = self.transform.warp_to_perspective(warped_lane_image)\n",
    "        # combine the result with the original undistorted image\n",
    "        result = cv2.addWeighted(undistorted, 1, perspective_lane_image, 0.3, 0)\n",
    "        # write properties of the detected lane directly into the picture\n",
    "        self.lane.display_lane_properties(result)\n",
    "        if self.show_debug_images:\n",
    "            #debug_show_images(undistorted, 'Undistorted Image', result, 'Detected Lane')\n",
    "            pass\n",
    "\n",
    "        if self.write_result:\n",
    "            result_path = out_folder + 'result_' + source_file\n",
    "            print(\"Writing to result_path=\", result_path);\n",
    "            cv2.imwrite(result_path, result)\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Process pictures\n",
    "#\n",
    "\n",
    "\n",
    "camera = Camera()\n",
    "camera.initialize_calibration_parameters()\n",
    "\n",
    "in_folder = \"test_images/\"\n",
    "out_folder = \"output_images/\"\n",
    "\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "\n",
    "source_files = os.listdir(in_folder)\n",
    "\n",
    "# Read and process sample images\n",
    "for source_file in source_files:\n",
    "\n",
    "    # read test image in\n",
    "    source_path = in_folder + source_file\n",
    "    print(\"Reading from source_path=\", source_path);\n",
    "    img = cv2.cvtColor(cv2.imread(source_path),cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    image_processor = ImageProcessor(camera, img.shape[1], img.shape[0], show_debug_images = True, write_undistorted = True, write_thresholded = True, write_birds_eye_view = True, write_result = True)\n",
    "    image_processor.process_image(img)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Process videos\n",
    "#\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "#from IPython.display import HTML\n",
    "\n",
    "#input_clip = VideoFileClip(\"project_video.mp4\").subclip(39,40)\n",
    "input_clip = VideoFileClip(\"project_video.mp4\")\n",
    "output_path = \"output_project_video.mp4\"\n",
    "\n",
    "# calculate region of interest\n",
    "ysize = input_clip.h\n",
    "xsize = input_clip.w\n",
    "\n",
    "near_distance = ysize-1\n",
    "far_distance = ysize*0.6\n",
    "mid_x = (xsize-1)/2\n",
    "\n",
    "left_bottom = [0, near_distance]\n",
    "right_bottom = [xsize-1, near_distance]\n",
    "\n",
    "left_apex = [mid_x-35, far_distance]\n",
    "right_apex = [mid_x+35, far_distance]\n",
    "\n",
    "vertices = np.array( [[left_bottom, left_apex, right_apex, right_bottom, left_bottom]], dtype=np.int32 )\n",
    "\n",
    "# init processing pipeline with region of interest and stabilization buffer length\n",
    "camera = Camera()\n",
    "camera.initialize_calibration_parameters()\n",
    "image_processor = ImageProcessor(camera, xsize, ysize, show_debug_images = True, write_undistorted = False, write_thresholded = False, write_birds_eye_view = False, write_result = False)\n",
    "\n",
    "output_clip = input_clip.fl_image(image_processor.process_image) #NOTE: this function expects color images!!\n",
    "%time output_clip.write_videofile(output_path, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
